{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\digig\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import imageio.v2 as io \n",
    "import json\n",
    "import yaml\n",
    "from skimage.transform import resize\n",
    "from tqdm.auto import tqdm\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from Lib.LoadDIODE import *\n",
    "from Lib.VisualizationDIODE import *\n",
    "from Lib.ModelsDIODE import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read yaml file\n",
      "{'train_scenes': ['scene_00000', 'scene_00001', 'scene_00006', 'scene_00004'], 'val_scenes': ['scene_00002', 'scene_00003'], 'test_scenes': ['scene_00005'], 'enable_aug_train': True, 'enable_aug_val': False, 'enable_aug_test': False, 'clamp': True, 'percentuale': 1, 'batch_size': 8, 'shuffle': True, 'show_clip': True, 'en_clip': False, 'enable_BatchNorm2d_alllayer': True, 'enable_Dropout_alllayer': True, 'decrease_dropout': 1, 'value_dropout': 0.5, 'criterion': 'L1Loss()', 'lr': 0.0001, 'weight_decay': 0.005, 'patience_sched': 5, 'factor_sched': 0.2, 'verbose_sched': True, 'num_epochs': 2, 'patience_earlt': 5, 'size': (384, 512)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(str(\"../hyp/Config.yaml\"), 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "print(\"Read yaml file\" )\n",
    "\n",
    "train_scenes = config[\"train_scenes\"]\n",
    "val_scenes = config[\"val_scenes\"]\n",
    "test_scenes = config[\"test_scenes\"]\n",
    "enable_aug_train = config[\"enable_aug_train\"]\n",
    "enable_aug_val = config[\"enable_aug_val\"]\n",
    "enable_aug_test = config[\"enable_aug_test\"]\n",
    "clamp = config[\"clamp\"]\n",
    "percentuale = config[\"percentuale\"]\n",
    "batch_size = config[\"batch_size\"]\n",
    "shuffle = config[\"shuffle\"]\n",
    "show_clip = config[\"show_clip\"]\n",
    "en_clip = config[\"en_clip\"]\n",
    "enable_BatchNorm2d_alllayer = config[\"enable_BatchNorm2d_alllayer\"]\n",
    "enable_Dropout_alllayer = config[\"enable_Dropout_alllayer\"]\n",
    "decrease_dropout = config[\"decrease_dropout\"]\n",
    "value_dropout = config[\"value_dropout\"]\n",
    "criterion = nn.L1Loss() \n",
    "lr = config[\"lr\"]\n",
    "weight_decay = config[\"weight_decay\"]\n",
    "patience_sched = config[\"patience_sched\"]\n",
    "factor_sched = config[\"factor_sched\"]\n",
    "verbose_sched = config[\"verbose_sched\"]\n",
    "num_epochs = 2#config[\"num_epochs\"]\n",
    "patience_earlt = config[\"patience_earlt\"]\n",
    "size = tuple(config[\"size\"])\n",
    "path_dataset=config[\"path_dataset\"]\n",
    "path_dst = config[\"path_dst\"]\n",
    "csv_path=config[\"csv_path\"]\n",
    "csv_path_aug=config[\"csv_path_aug\"]\n",
    "csv_path_not_aug=config[\"csv_path_not_aug\"]\n",
    "kaggle=config[\"kaggle\"]\n",
    "model_type=config[\"model_type\"]\n",
    "\n",
    "config_dict = {\n",
    "    \"train_scenes\": train_scenes,\n",
    "    \"val_scenes\": val_scenes,\n",
    "    \"test_scenes\": test_scenes,\n",
    "    \"enable_aug_train\": enable_aug_train,\n",
    "    \"enable_aug_val\": enable_aug_val,\n",
    "    \"enable_aug_test\": enable_aug_test,\n",
    "    \"clamp\": clamp,\n",
    "    \"percentuale\": percentuale,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"shuffle\": shuffle,\n",
    "    \"show_clip\": show_clip,\n",
    "    \"en_clip\": en_clip,\n",
    "    \"enable_BatchNorm2d_alllayer\": enable_BatchNorm2d_alllayer,\n",
    "    \"enable_Dropout_alllayer\": enable_Dropout_alllayer,\n",
    "    \"decrease_dropout\": decrease_dropout,\n",
    "    \"value_dropout\": value_dropout,\n",
    "    \"criterion\": str(criterion),\n",
    "    \"lr\": lr,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"patience_sched\": patience_sched,\n",
    "    \"factor_sched\": factor_sched,\n",
    "    \"verbose_sched\": verbose_sched,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"patience_earlt\": patience_earlt,\n",
    "    \"size\": size\n",
    "}\n",
    "\n",
    "csv_train_path=path_dst+\"path_train.csv\"\n",
    "csv_val_path=path_dst+\"path_val.csv\"\n",
    "csv_test_path=path_dst+\"path_test.csv\"\n",
    "\n",
    "print(config_dict)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_df_ipcv_diode(path_dataset,path_dst=path_dst)   \n",
    "train_val_test_split(csv_path_aug, csv_path_not_aug, path_dst=path_dst,enable_aug_train=enable_aug_train, enable_aug_val=enable_aug_val, enable_aug_test=enable_aug_test)\n",
    "# faccio clipping sulla depth_map \n",
    "if en_clip:\n",
    "    train_set =CustomDataset(csv_train_path, perc_dataset=percentuale, transform=rgb_transformations_base(size,device), target_transform=depth_map_transformations_clip(size,device))\n",
    "    val_set = CustomDataset(csv_val_path, perc_dataset=percentuale, transform=rgb_transformations_base(size,device), target_transform=depth_map_transformations_clip(size,device))\n",
    "else:\n",
    "    train_set = CustomDataset(csv_train_path, perc_dataset=percentuale, transform=rgb_transformations_base(size,device), target_transform=depth_map_transformations_no_clip(size,device))\n",
    "    val_set = CustomDataset(csv_val_path, perc_dataset=percentuale, transform=rgb_transformations_base(size,device), target_transform=depth_map_transformations_no_clip(size,device))\n",
    "test_set = CustomDataset(csv_test_path, perc_dataset=1, transform=rgb_transformations_test(device), target_transform=depth_map_transformations_test(device))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=shuffle)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=shuffle)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=shuffle)\n",
    "print('Img train :' ,len(train_set),'\\t Img val :', len(val_set),'\\t Img test :', len(test_set),\"\\t Totale :\",len(train_set)+len(val_set)+len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.89399 | Val loss: 1.53008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.55354 | Val loss: 1.55182\n"
     ]
    }
   ],
   "source": [
    "new_experiment_path=create_folder_experiment(kaggle,config_dict)\n",
    "\n",
    "while model_type not in ['Dense121','Base','Skip']:\n",
    "    model_type=input('Inserisci Dense121/Base/Skip :')\n",
    "if model_type=='Dense121':\n",
    "    model = Densenet121_Decoder(enable_BatchNorm2d_alllayer=enable_BatchNorm2d_alllayer,enable_Dropout_alllayer=enable_Dropout_alllayer,decrease_dropout=decrease_dropout,value_dropout=value_dropout)\n",
    "elif model_type=='Base':\n",
    "    model=Encoder_Decoder()\n",
    "elif model_type=='Skip':\n",
    "    model=ED_SkippConnection()\n",
    "\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=patience_sched, factor=factor_sched, verbose=True)\n",
    "list_loss_train,list_loss_val,val_images,val_img_rgbd,val_outputs,train_img,train_true,train_output=train(model, criterion, optimizer, train_loader, val_loader, num_epochs, patience_earlt, scheduler,new_experiment_path)\n",
    "\n",
    "save_epoch(list_loss_train,list_loss_val,save_path=new_experiment_path)\n",
    "print_dataset_pred(model,train_loader,rows = 4,offset=0,save_path=new_experiment_path,name='train')\n",
    "print_dataset_pred(model,train_loader,rows = 4,offset=10,save_path=new_experiment_path,name='train')\n",
    "print_dataset_pred(model,train_loader,rows = 4,offset=20,save_path=new_experiment_path,name='train')\n",
    "print_dataset_pred(model,val_loader,rows = 4,offset=0,save_path=new_experiment_path,name='val')\n",
    "print_dataset_pred(model,val_loader,rows = 4,offset=10,save_path=new_experiment_path,name='val')\n",
    "print_dataset_pred(model,val_loader,rows = 4,offset=20,save_path=new_experiment_path,name='val')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
