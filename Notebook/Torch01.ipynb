{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install pillow\n","!pip install numpy\n","!pip install -U scikit-learn\n","!python -m pip install \"tensorflow<2.11\""]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Libraries"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T20:39:37.317383Z","iopub.status.busy":"2023-05-08T20:39:37.317020Z","iopub.status.idle":"2023-05-08T20:39:37.521133Z","shell.execute_reply":"2023-05-08T20:39:37.519893Z","shell.execute_reply.started":"2023-05-08T20:39:37.317354Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'NVIDIA GeForce GTX 1650 SUPER'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["from PIL import Image\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","from sklearn.model_selection import train_test_split\n","\n","import cv2\n","import torch\n","import torch.nn as nn\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","\n","\n","from Library import CustomDataset\n","\n","torch.cuda.get_device_name(0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Conversion in dataset"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-05-08T18:56:13.470401Z","iopub.status.busy":"2023-05-08T18:56:13.469406Z","iopub.status.idle":"2023-05-08T18:56:19.045272Z","shell.execute_reply":"2023-05-08T18:56:19.044033Z","shell.execute_reply.started":"2023-05-08T18:56:13.470369Z"},"trusted":true},"outputs":[],"source":["path='../Dataset/indoors/'\n","create_df_ipcv_diode(path)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Split dataset"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["csv_path=\"../Csv/path_images.csv\"\n","custom_dataset = CustomDataset(csv_path, test_size=0.3, random_state=42)\n","train_loader = torch.utils.data.DataLoader(custom_dataset, batch_size=16, shuffle=True)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","\n","class ImageConverter(nn.Module):\n","    def __init__(self):\n","        super(ImageConverter, self).__init__()\n","        \n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","        \n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(32, 1, kernel_size=1, stride=1)\n","        )\n","    \n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","\n","class ImageConverter(nn.Module):\n","    def __init__(self):\n","        super(ImageConverter, self).__init__()\n","        \n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","        \n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(32, 1, kernel_size=1, stride=1)\n","        )\n","    \n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["model = ImageConverter()\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","num_epochs = 5\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"cannot unpack non-iterable int object","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[32], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m      7\u001b[0m     train_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mfor\u001b[39;00m i, (images, _) \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(custom_dataset)):\n\u001b[0;32m      9\u001b[0m         images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\u001b[39m# Trasferisci i dati al dispositivo\u001b[39;00m\n\u001b[0;32m     10\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\u001b[39m# Resetta i gradienti\u001b[39;00m\n","\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable int object"]}],"source":["# Imposta il dispositivo (GPU o CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Addestra il modello\n","for epoch in range(num_epochs):\n","    train_loss = 0.0\n","    for i, (images, _) in enumerate(train_loader):\n","        images = images.to(device)# Trasferisci i dati al dispositivo\n","        optimizer.zero_grad()# Resetta i gradienti\n","        outputs = model(images)# Propaga in avanti\n","        loss = criterion(outputs, images)# Calcola la loss\n","        loss.backward()        # Propaga all'indietro e ottieni i gradienti\n","        optimizer.step()# Aggiorna i pesi\n","        train_loss += loss.item() * images.size(0)# Aggiorna la loss\n","\n","    train_loss = train_loss / len(train_loader.dataset) # Calcola la loss media per epoca\n"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"ename":"IndexError","evalue":"list index out of range","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m      2\u001b[0m     images, labels \u001b[39m=\u001b[39m batch\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[1;32mf:\\IPCV\\Notebook\\Library.py:57\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX_train_rgb[idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train_depth[idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train_rgbds[idx]\n","\u001b[1;31mIndexError\u001b[0m: list index out of range"]}],"source":["for i, batch in enumerate(train_loader):\n","    images, labels = batch"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(custom_dataset, batch_size=16, shuffle=True, drop_last=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
